{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4 Question 3 Part 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mujahidrj/Artificial-Intelligence/blob/master/HW4/HW4_Question_3_Part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGPyPFSaxbD8",
        "colab_type": "text"
      },
      "source": [
        "# Problem 3 Part 1\n",
        "\n",
        "You will adapt the notebook using VGG16 conv base for feature extraction, using data augmentation, not using dropout, fine-tuning. You will have to replace the VGG16 conv base by new conv bases. You should not use VGG19.\n",
        "\n",
        "You should create two notebooks. Both should use the same conv base, unfreeze the same number of layers of the conv_base, but use different classifiers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSrgMJ5vKFzQ",
        "colab_type": "text"
      },
      "source": [
        "# Fine-tuning Xception \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIW7bZaAK-Hf",
        "colab_type": "text"
      },
      "source": [
        "This is based on section 5.3 *Using a pretrained convnet* of the book *Deep learning with Python* by Francois Chollet. I have made several changes to the code. I use the data that is already provided by Google. I don't download the data from Kaggle as in the deep learning book."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsBq__dVo2pj",
        "colab_type": "text"
      },
      "source": [
        "## Feature extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g6ETAM9o54M",
        "colab_type": "text"
      },
      "source": [
        "Feature extraction consists of using the representations learned by a previous network to extract interesting features from new samples. These features are then run through a new classifier, which is trained from scratch.\n",
        "\n",
        "We will use here the convolutional base of the Xception model to extract the features. We will feed these features to a densely connected classifier with dropout. We will fine-tune some layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqIG8QHMLNOn",
        "colab_type": "text"
      },
      "source": [
        "## Download the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3I1jd7cKV6_",
        "colab_type": "text"
      },
      "source": [
        "Download the example data, a zip. of 2,000 JPG pictures of cats and dogs and extract it locally in ```/tmp```.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWjprHEXJ5Qi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f7d832dc-b3c5-4def-b0ec-daff8bed0949"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-22 03:21:56--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.69.128, 2a00:1450:4013:c01::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.69.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "\r          /tmp/cats   0%[                    ]       0  --.-KB/s               \r         /tmp/cats_  90%[=================>  ]  59.45M   297MB/s               \r/tmp/cats_and_dogs_ 100%[===================>]  65.43M   306MB/s    in 0.2s    \n",
            "\n",
            "2020-04-22 03:21:56 (306 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvoHtdA-K6Rw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shZiOBnJMyy_",
        "colab_type": "text"
      },
      "source": [
        "Note that the data provided by Google does not have a test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL8ikM89LlsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Directory with our training cat pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "\n",
        "# Directory with our training dog pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Directory with our validation cat pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "\n",
        "# Directory with our validation dog pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inyP8bcdXnn-",
        "colab_type": "text"
      },
      "source": [
        "## Build network with Xception convolution base and custom densely connected layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ48W5T9rHWu",
        "colab_type": "text"
      },
      "source": [
        "### Load the convolutional base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0FgtANCXm_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "53a4953a-cde7-4d45-b06b-cb55d309bd06"
      },
      "source": [
        "from keras.applications import Xception\n",
        "\n",
        "conv_base = Xception(\n",
        "    weights='imagenet', \n",
        "    include_top=False, \n",
        "    input_shape=(150, 150, 3))\n",
        "\n",
        "conv_base.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"xception\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, 74, 74, 32)   128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, 74, 74, 32)   0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 72, 72, 64)   18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, 72, 72, 64)   256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, 72, 72, 64)   0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, 72, 72, 128)  8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, 72, 72, 128)  0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, 72, 72, 128)  17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 36, 36, 128)  8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 36, 36, 128)  0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 36, 36, 128)  512         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 36, 36, 128)  0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, 36, 36, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, 36, 36, 256)  33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, 36, 36, 256)  0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, 36, 36, 256)  67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 18, 18, 256)  32768       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 18, 18, 256)  0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 18, 18, 256)  1024        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 18, 18, 256)  0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, 18, 18, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, 18, 18, 728)  188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, 18, 18, 728)  0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, 18, 18, 728)  536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 9, 9, 728)    186368      add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 9, 9, 728)    0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 9, 9, 728)    2912        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 9, 9, 728)    0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, 9, 9, 728)    0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, 9, 9, 728)    0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, 9, 9, 728)    0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 9, 9, 728)    0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, 9, 9, 728)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, 9, 9, 728)    0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, 9, 9, 728)    0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 9, 9, 728)    0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, 9, 9, 728)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, 9, 9, 728)    0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, 9, 9, 728)    0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 9, 9, 728)    0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, 9, 9, 728)    0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, 9, 9, 728)    0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, 9, 9, 728)    0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 9, 9, 728)    0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, 9, 9, 728)    0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, 9, 9, 728)    0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, 9, 9, 728)    0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 9, 9, 728)    0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, 9, 9, 728)    0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, 9, 9, 728)    0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 9, 9, 728)    0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, 9, 9, 728)    0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, 9, 9, 728)    0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 9, 9, 728)    0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, 9, 9, 728)    0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, 9, 9, 728)    0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 9, 9, 728)    0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, 9, 9, 728)    0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, 9, 9, 1024)   752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, 9, 9, 1024)   4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 5, 5, 1024)   745472      add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, 5, 5, 1024)   0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 5, 5, 1024)   4096        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 5, 5, 1024)   0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, 5, 5, 1536)   1582080     add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, 5, 5, 1536)   6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, 5, 5, 1536)   0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, 5, 5, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, 5, 5, 2048)   8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, 5, 5, 2048)   0           block14_sepconv2_bn[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 20,861,480\n",
            "Trainable params: 20,806,952\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6OBHOO9q1ou",
        "colab_type": "text"
      },
      "source": [
        "### Freeze the convolutional base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UleRo4Dpq6Ld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qfx6PqhPrb7Q",
        "colab_type": "text"
      },
      "source": [
        "### Concatenate the convolutional base and densely connected layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUpmocDAO3xm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "# Changed the following layer\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "#model.add(layers.Dropout(0.1))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh6gZSeAjF7c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "6ac65098-7ce6-43dc-f6df-d576b3bc642f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "xception (Model)             (None, 5, 5, 2048)        20861480  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              52429824  \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 1025      \n",
            "=================================================================\n",
            "Total params: 73,292,329\n",
            "Trainable params: 52,430,849\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZjBiddhi5Qj",
        "colab_type": "text"
      },
      "source": [
        "## Train the model end to end with frozen convolutional base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfAQlC2Oi41L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fff82a5a-adae-48de-8ff6-8993337b3db1"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "\n",
        "# data augmentation\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255, \n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')\n",
        "\n",
        "# compile model\n",
        "\n",
        "# Higher learning rate than what is used later on\n",
        "model.compile(\n",
        "    loss='binary_crossentropy', \n",
        "    optimizer=optimizers.RMSprop(lr=2e-5), \n",
        "    metrics=['acc'])\n",
        "\n",
        "# train\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Epoch 1/30\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.5109 - acc: 0.7710 - val_loss: 0.0095 - val_acc: 0.9520\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.3624 - acc: 0.8335 - val_loss: 0.0088 - val_acc: 0.9110\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.3670 - acc: 0.8375 - val_loss: 0.0864 - val_acc: 0.9600\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.3271 - acc: 0.8585 - val_loss: 0.3081 - val_acc: 0.9710\n",
            "Epoch 5/30\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.3095 - acc: 0.8690 - val_loss: 0.0516 - val_acc: 0.9660\n",
            "Epoch 6/30\n",
            "100/100 [==============================] - 17s 175ms/step - loss: 0.3295 - acc: 0.8555 - val_loss: 0.0793 - val_acc: 0.9700\n",
            "Epoch 7/30\n",
            "100/100 [==============================] - 17s 175ms/step - loss: 0.2995 - acc: 0.8680 - val_loss: 0.0257 - val_acc: 0.9660\n",
            "Epoch 8/30\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.2968 - acc: 0.8705 - val_loss: 2.3560e-05 - val_acc: 0.9710\n",
            "Epoch 9/30\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.3109 - acc: 0.8620 - val_loss: 1.4473 - val_acc: 0.9380\n",
            "Epoch 10/30\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.2980 - acc: 0.8735 - val_loss: 0.2554 - val_acc: 0.9400\n",
            "Epoch 11/30\n",
            "100/100 [==============================] - 18s 175ms/step - loss: 0.2824 - acc: 0.8800 - val_loss: 1.5700 - val_acc: 0.9640\n",
            "Epoch 12/30\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.3018 - acc: 0.8710 - val_loss: 2.2157e-07 - val_acc: 0.9600\n",
            "Epoch 13/30\n",
            "100/100 [==============================] - 17s 175ms/step - loss: 0.2816 - acc: 0.8795 - val_loss: 1.1025 - val_acc: 0.9720\n",
            "Epoch 14/30\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.2815 - acc: 0.8780 - val_loss: 0.0463 - val_acc: 0.9710\n",
            "Epoch 15/30\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.3080 - acc: 0.8755 - val_loss: 0.4097 - val_acc: 0.9680\n",
            "Epoch 16/30\n",
            "100/100 [==============================] - 17s 175ms/step - loss: 0.2751 - acc: 0.8840 - val_loss: 2.1815e-08 - val_acc: 0.9630\n",
            "Epoch 17/30\n",
            "100/100 [==============================] - 17s 175ms/step - loss: 0.2845 - acc: 0.8855 - val_loss: 0.0025 - val_acc: 0.9690\n",
            "Epoch 18/30\n",
            "100/100 [==============================] - 17s 175ms/step - loss: 0.2685 - acc: 0.8855 - val_loss: 3.8269e-08 - val_acc: 0.9740\n",
            "Epoch 19/30\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.2608 - acc: 0.8905 - val_loss: 0.0337 - val_acc: 0.9570\n",
            "Epoch 20/30\n",
            "100/100 [==============================] - 18s 175ms/step - loss: 0.2779 - acc: 0.8825 - val_loss: 1.9483 - val_acc: 0.9730\n",
            "Epoch 21/30\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 0.2637 - acc: 0.8935 - val_loss: 2.9697e-10 - val_acc: 0.9680\n",
            "Epoch 22/30\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 0.2675 - acc: 0.8890 - val_loss: 0.1866 - val_acc: 0.9730\n",
            "Epoch 23/30\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 0.2731 - acc: 0.8815 - val_loss: 0.2534 - val_acc: 0.9720\n",
            "Epoch 24/30\n",
            "100/100 [==============================] - 18s 175ms/step - loss: 0.2529 - acc: 0.8855 - val_loss: 0.0014 - val_acc: 0.9740\n",
            "Epoch 25/30\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 0.2775 - acc: 0.8890 - val_loss: 0.5997 - val_acc: 0.9730\n",
            "Epoch 26/30\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.2321 - acc: 0.9015 - val_loss: 1.4333e-09 - val_acc: 0.9720\n",
            "Epoch 27/30\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.2746 - acc: 0.8935 - val_loss: 0.0101 - val_acc: 0.9700\n",
            "Epoch 28/30\n",
            "100/100 [==============================] - 17s 175ms/step - loss: 0.2677 - acc: 0.8925 - val_loss: 0.2042 - val_acc: 0.9740\n",
            "Epoch 29/30\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 0.2684 - acc: 0.8915 - val_loss: 0.1309 - val_acc: 0.9520\n",
            "Epoch 30/30\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 0.2636 - acc: 0.8920 - val_loss: 0.0029 - val_acc: 0.9710\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqRc_vHKc92U",
        "colab_type": "text"
      },
      "source": [
        "## Display curves of loss and accuracy during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybWwdzz9bwuQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "b1d277c1-30d8-4cad-be70-dad42a8ed686"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# training and validation accuracy\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='validation acc')\n",
        "plt.title('training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# training and validation loss\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOWsxpey8lN0",
        "colab_type": "text"
      },
      "source": [
        "## Fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SFUw6COkGz7",
        "colab_type": "text"
      },
      "source": [
        "Fine tuning results are usually done if the data set being used isn't very different than the data from the pre-trained model. One problem with fine tuning results is that using a small dataset can lead to overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwkVMx8N8qMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "  if layer.name == 'block13_sepconv2':\n",
        "    set_trainable = True\n",
        "  if set_trainable:\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyN-J7rs9cvo",
        "colab_type": "code",
        "outputId": "3f50bbb1-2df5-4bd7-f489-db6172f772f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# compile model\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    #\n",
        "    # choose a smaller learning rate\n",
        "    #\n",
        "    optimizer=optimizers.RMSprop(lr=1e-5), \n",
        "    metrics=['acc'])\n",
        "\n",
        "# train\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=100,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.2424 - acc: 0.9010 - val_loss: 8.5933e-05 - val_acc: 0.9430\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.2378 - acc: 0.9035 - val_loss: 0.0019 - val_acc: 0.9460\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.1976 - acc: 0.9210 - val_loss: 0.3172 - val_acc: 0.9410\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.2288 - acc: 0.9075 - val_loss: 0.5045 - val_acc: 0.9410\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.2363 - acc: 0.9035 - val_loss: 0.0772 - val_acc: 0.9370\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.2011 - acc: 0.9210 - val_loss: 0.2103 - val_acc: 0.9240\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.2043 - acc: 0.9180 - val_loss: 0.1106 - val_acc: 0.9280\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.1973 - acc: 0.9190 - val_loss: 0.1491 - val_acc: 0.9400\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.1771 - acc: 0.9280 - val_loss: 0.5456 - val_acc: 0.9390\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.1931 - acc: 0.9210 - val_loss: 0.2236 - val_acc: 0.9400\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.1803 - acc: 0.9310 - val_loss: 0.0519 - val_acc: 0.9230\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.1789 - acc: 0.9235 - val_loss: 0.0938 - val_acc: 0.9410\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.1799 - acc: 0.9290 - val_loss: 0.9559 - val_acc: 0.9310\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.1878 - acc: 0.9185 - val_loss: 0.5836 - val_acc: 0.9370\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.1987 - acc: 0.9295 - val_loss: 0.2832 - val_acc: 0.9320\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.1796 - acc: 0.9245 - val_loss: 0.4859 - val_acc: 0.9380\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.1684 - acc: 0.9420 - val_loss: 0.1632 - val_acc: 0.8930\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.1645 - acc: 0.9415 - val_loss: 0.0515 - val_acc: 0.9360\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.1855 - acc: 0.9330 - val_loss: 0.3832 - val_acc: 0.9350\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.1699 - acc: 0.9335 - val_loss: 0.2055 - val_acc: 0.9370\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.1749 - acc: 0.9315 - val_loss: 0.0575 - val_acc: 0.9190\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.1603 - acc: 0.9385 - val_loss: 0.1278 - val_acc: 0.9380\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.1742 - acc: 0.9360 - val_loss: 0.0411 - val_acc: 0.9450\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.1452 - acc: 0.9420 - val_loss: 0.5606 - val_acc: 0.9430\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.1407 - acc: 0.9440 - val_loss: 0.4320 - val_acc: 0.9470\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.1555 - acc: 0.9370 - val_loss: 0.2548 - val_acc: 0.9400\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.1793 - acc: 0.9360 - val_loss: 0.0917 - val_acc: 0.9300\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.1344 - acc: 0.9460 - val_loss: 0.0383 - val_acc: 0.9480\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.1550 - acc: 0.9445 - val_loss: 0.1601 - val_acc: 0.9260\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 18s 184ms/step - loss: 0.1418 - acc: 0.9425 - val_loss: 0.1369 - val_acc: 0.9310\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.1641 - acc: 0.9345 - val_loss: 0.0251 - val_acc: 0.9250\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.1502 - acc: 0.9445 - val_loss: 0.9156 - val_acc: 0.9480\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.1409 - acc: 0.9470 - val_loss: 0.1834 - val_acc: 0.9330\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.1526 - acc: 0.9425 - val_loss: 0.3813 - val_acc: 0.9470\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.1300 - acc: 0.9500 - val_loss: 0.2203 - val_acc: 0.9430\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.1398 - acc: 0.9440 - val_loss: 0.6141 - val_acc: 0.9410\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.1536 - acc: 0.9465 - val_loss: 1.7213 - val_acc: 0.9470\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.1359 - acc: 0.9525 - val_loss: 0.0111 - val_acc: 0.9460\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.1091 - acc: 0.9605 - val_loss: 0.0044 - val_acc: 0.9450\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.1445 - acc: 0.9475 - val_loss: 0.0929 - val_acc: 0.9430\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.1246 - acc: 0.9560 - val_loss: 0.0249 - val_acc: 0.9370\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.1347 - acc: 0.9480 - val_loss: 0.1673 - val_acc: 0.9250\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.1214 - acc: 0.9530 - val_loss: 0.0746 - val_acc: 0.9330\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.1454 - acc: 0.9490 - val_loss: 0.0292 - val_acc: 0.9310\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.1099 - acc: 0.9585 - val_loss: 0.0302 - val_acc: 0.9460\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.1233 - acc: 0.9530 - val_loss: 0.0136 - val_acc: 0.9440\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.1303 - acc: 0.9565 - val_loss: 0.1379 - val_acc: 0.9490\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.1109 - acc: 0.9575 - val_loss: 0.2673 - val_acc: 0.9440\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.1354 - acc: 0.9470 - val_loss: 3.9669e-04 - val_acc: 0.9460\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.1103 - acc: 0.9555 - val_loss: 0.5722 - val_acc: 0.9490\n",
            "Epoch 51/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 0.1213 - acc: 0.9587"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVBQgh5M-Rtz",
        "colab_type": "text"
      },
      "source": [
        "## Display learning curves during fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbkIw7Ie-NP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# training and validation accuracy\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='validation acc')\n",
        "plt.title('training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# training and validation loss\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PL60g3RDrtzd",
        "colab_type": "text"
      },
      "source": [
        "#Print out validation loss and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG7byb3_roKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_loss, val_acc = model.evaluate_generator(validation_generator, steps=50)\n",
        "print(\"Validation loss:\", val_loss)\n",
        "print(\"Validation accuracy:\", val_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anlnG-12r-Qa",
        "colab_type": "text"
      },
      "source": [
        "# Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVI6GC_Rr9fv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_fname = 'cats_and_dogs_small_4.h5' \n",
        "model.save(model_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmeKtuNs9Qm1",
        "colab_type": "text"
      },
      "source": [
        "To download the model, uncomment the code below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKYzmt07xZZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# with open(model_fname, 'r') as f:\n",
        "#   files.download(model_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}